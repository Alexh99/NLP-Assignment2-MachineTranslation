The tables below summarize the BLEU scores that each
translation recieved with different number of sentences
used for the allignment model, and different values of 
n in the BLEU score calculation. 

The tables show us that as the number of sentences used 
for the allignment model increase, the BLEU scores increase
as well. The reason for this is because the model has
a larger corpus to train on and sees more examples of
English and French translation.

Another point to note is that as n increases the BLEU
score decreases. The reason for this is because n is 
the number of words that appear correctly in the 
candidate sentence given the reference sentences. 
Having three correct words back-to-back has a lower
probability than just having one word correct.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

numSentences = 1000

Line	|	n=1		|	n=2		|	n=3		|
---------------------------------------------
1		|	0.2000	|	0		|	0		|
2		|	0.4954	|	0.2675	|	0		|
3		|	0.4545	|	0		|	0		|
4		|	0.3067	|	0.1602	|	0		|
5		|	0.3032	|	0		|	0		|
6		|	0.3309	|	0		|	0		|
7		|	0.2490	|	0		|	0		|
8		|	0.2388	|	0		|	0		|
9		|	0.2388	|	0		|	0		|
10		|	0.2500	|	0		|	0		|
11		|	0.4545	|	0.2132	|	0		|
12		|	0.3333	|	0		|	0		|
13		|	0.1103	|	0		|	0		|
14		|	0.3125	|	0.1443	|	0		|
15		|	0.3790	|	0.1778	|	0		|
16		|	0.4000	|	0		|	0		|
17		|	0.3894	|	0.2081	|	0		|
18		|	0.3719	|	0.2348	|	0		|
19		|	0.1384	|	0		|	0		|
20		|	0.5000	|	0		|	0		|
21		|	0.2388	|	0		|	0		|
22		|	0.3559	|	0.1887	|	0		|
23		|	0.2822	|	0		|	0		|
24		|	0.3125	|	0		|	0		|
25		|	0.1667	|	0		|	0		|



numSentences = 10,000

Line	|	n=1		|	n=2		|	n=3		|
---------------------------------------------
1		|	0.2667	|	0		|	0		|
2		|	0.3715	|	0.2317	|	0		|
3		|	0.4545	|	0		|	0		|
4		|	0.5367	|	0.2996	|	0		|
5		|	0.3032	|	0		|	0		|
6		|	0.5516	|	0.2637	|	0		|
7		|	0.2490	|	0		|	0		|
8		|	0.2388	|	0		|	0		|
9		|	0.1194	|	0		|	0		|
10		|	0.3750	|	0.2315	|	0		|
11		|	0.4545	|	0		|	0		|
12		|	0.4167	|	0		|	0		|
13		|	0.1103	|	0		|	0		|
14		|	0.3750	|	0.2236	|	0		|
15		|	0.3032	|	0.1590	|	0		|
16		|	0.5000	|	0.3333	|	0		|
17		|	0.2921	|	0.1803	|	0		|
18		|	0.5114	|	0.2753	|	0		|
19		|	0.2076	|	0		|	0		|
20		|	0.5000	|	0		|	0		|
21		|	0.4777	|	0.2616	|	0		|
22		|	0.6228	|	0.3531	|	0		|
23		|	0.3527	|	0.1647	|	0		|
24		|	0.3125	|	0		|	0		|
25		|	0.1667	|	0		|	0		|



numSentences = 15,000

Line	|	n=1		|	n=2		|	n=3		|
---------------------------------------------
1		|	0.2667	|	0		|	0		|
2		|	0.3715	|	0.3276	|	0.2650	|
3		|	0.6364	|	0.2523	|	0		|
4		|	0.6134	|	0.3203	|	0		|
5		|	0.2774	|	0		|	0		|
6		|	0.4412	|	0		|	0		|
7		|	0.2490	|	0		|	0		|
8		|	0.2388	|	0		|	0		|
9		|	0.1194	|	0		|	0		|
10		|	0.3750	|	0.2315	|	0		|
11		|	0.5455	|	0.2335	|	0		|
12		|	0.4167	|	0.1946	|	0		|
13		|	0.2206	|	0		|	0		|
14		|	0.3750	|	0.2236	|	0		|
15		|	0.3032	|	0.1590	|	0		|
16		|	0.2000	|	0		|	0		|
17		|	0.1947	|	0.1472	|	0		|
18		|	0.3719	|	0.1917	|	0		|
19		|	0.1384	|	0		|	0		|
20		|	0.6250	|	0.2988	|	0		|
21		|	0.5971	|	0.5067	|	0.3583	|
22		|	0.6228	|	0.4324	|	0		|
23		|	0.4232	|	0.2552	|	0		|
24		|	0.5000	|	0.1826	|	0		|
25		|	0.1667	|	0		|	0		|

numSentences = 30,000

Line	|	n=1		|	n=2		|	n=3		|
---------------------------------------------
1		|	0.2667	|	0		|	0		|
2		|	0.3715	|	0.3276	|	0.2650	|
3		|	0.6364	|	0.2523	|	0		|
4		|	0.5367	|	0.4237	|	0.3209	|
5		|	0.4548	|	0		|	0		|
6		|	0.4412	|	0.3336	|	0.2539	|
7		|	0.3320	|	0		|	0		|
8		|	0.3583	|	0.2266	|	0		|
9		|	0.2338	|	0		|	0		|
10		|	0.2500	|	0.1890	|	0		|
11		|	0.3636	|	0		|	0		|
12		|	0.3333	|	0		|	0		|
13		|	0.1103	|	0		|	0		|
14		|	0.3125	|	0.1443	|	0		|
15		|	0.3032	|	0.1590	|	0		|
16		|	0.3000	|	0		|	0		|
17		|	0.2921	|	0.1803	|	0		|
18		|	0.3719	|	0.2348	|	0		|
19		|	0.1384	|	0		|	0		|
20		|	0.5000	|	0		|	0		|
21		|	0.5971	|	0.5067	|	0.3583	|
22		|	0.6228	|	0.4324	|	0.2776	|
23		|	0.4232	|	0.2552	|	0		|
24		|	0.4375	|	0		|	0		|
25		|	0.1667	|	0		|	0		|